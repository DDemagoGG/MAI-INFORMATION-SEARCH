$ ./cxx/build/tokenizer data/corpus/raw_text.tsv data/processed/tokenized.txt
Tokenizer finished
documents=30646
tokens=27231515
avg_token_length=4.71447
elapsed_seconds=13.9602
seconds_per_kb=8.48932e-05
